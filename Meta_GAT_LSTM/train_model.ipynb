{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "D:\\app2018\\Anaconda35\\lib\\site-packages\\requests\\__init__.py:80: RequestsDependencyWarning: urllib3 (1.24.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from gat_lstm import STDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#城市，时间，站点，特征（5,6,7,8）\n",
    "def load_random_data(size):\n",
    "\n",
    "    adj = sp.random(size, size, density=0.1) # density similar to cora\n",
    "    features = sp.random(size, 32, density=0.5)\n",
    "    int_labels = np.random.randint(1, size=(size))\n",
    "    labels = np.random.rand(size, 1) # Nx7\n",
    "    labels[np.arange(size), int_labels] = 1\n",
    "\n",
    "    train_mask = np.zeros((size,)).astype(bool)\n",
    "    train_mask[np.arange(size)[0:int(size/2)]] = 1\n",
    "\n",
    "    val_mask = np.zeros((size,)).astype(bool)\n",
    "    val_mask[np.arange(size)[int(size/2):]] = 1\n",
    "\n",
    "    test_mask = np.zeros((size,)).astype(bool)\n",
    "    test_mask[np.arange(size)[int(size/2):]] = 1\n",
    "\n",
    "    y_train = np.zeros(labels.shape)\n",
    "    y_val = np.zeros(labels.shape)\n",
    "    y_test = np.zeros(labels.shape)\n",
    "    y_train[train_mask, :] = labels[train_mask, :]\n",
    "    y_val[val_mask, :] = labels[val_mask, :]\n",
    "    y_test[test_mask, :] = labels[test_mask, :]\n",
    "  \n",
    "    # sparse NxN, sparse NxF, norm NxC, ..., norm Nx1, ...\n",
    "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask\n",
    "\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return features.todense(), sparse_to_tuple(features)\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        return coords, values, shape\n",
    "\n",
    "def adj_to_bias(adj, sizes, nhood=1):\n",
    "    nb_graphs = adj.shape[0]\n",
    "    mt = np.empty(adj.shape)\n",
    "    for g in range(nb_graphs):\n",
    "        mt[g] = np.eye(adj.shape[1])\n",
    "        for _ in range(nhood):\n",
    "            mt[g] = np.matmul(mt[g], (adj[g] + np.eye(adj.shape[1])))\n",
    "        for i in range(sizes[g]):\n",
    "            for j in range(sizes[g]):\n",
    "                if mt[g][i][j] > 0.0:\n",
    "                    mt[g][i][j] = 1.0\n",
    "    return -1e9 * (1.0 - mt)\n",
    "    \n",
    "    \n",
    "    \n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_random_data(512)\n",
    "features, spars = preprocess_features(features)\n",
    "adj = adj.todense()\n",
    "#生成一维时间维度\n",
    "features = features[np.newaxis]\n",
    "adj = adj[np.newaxis]\n",
    "y_train = y_train[np.newaxis]\n",
    "y_val = y_val[np.newaxis]\n",
    "y_test = y_test[np.newaxis]\n",
    "train_mask = train_mask[np.newaxis]\n",
    "val_mask = val_mask[np.newaxis]\n",
    "test_mask = test_mask[np.newaxis]\n",
    "\n",
    "biases = adj_to_bias(adj, [32], nhood=1)\n",
    "\n",
    "#生成数据\n",
    "features = tf.reshape(features, [-1, 32,16])\n",
    "features = tf.dtypes.cast(features, tf.float32)\n",
    "sess = tf.Session()\n",
    "with sess.as_default():\n",
    "    features = features.eval()\n",
    "\n",
    "biases = np.reshape(biases,(-1,32,32))\n",
    "biases = biases[0:32]\n",
    "\n",
    "#y_train = np.asarray(y_train)\n",
    "y_train = np.reshape(y_train,(-1,32,1))[0:1]\n",
    "y_val = np.reshape(y_val,(-1,32,1))[0:1]\n",
    "y_test = np.reshape(y_test,(-1,32,1))[0:1]\n",
    "\n",
    "train_mask = np.reshape(train_mask,(16,32))\n",
    "val_mask = np.reshape(val_mask,(16,32))\n",
    "test_mask = np.reshape(test_mask,(16,32))\n",
    "\n",
    "#增加一维城市\n",
    "features = features[np.newaxis]\n",
    "adj = adj[np.newaxis]\n",
    "train_mask = train_mask[np.newaxis]\n",
    "val_mask = val_mask[np.newaxis]\n",
    "test_mask = test_mask[np.newaxis]\n",
    "biases = biases[np.newaxis]\n",
    "\n",
    "print(features.shape)\n",
    "print(biases.shape)\n",
    "print(y_train.shape)\n",
    "print(train_mask.shape)\n",
    "\n",
    "\n",
    "(cities,alltime,nodenum,features)\n",
    "(alltime,node,features)\n",
    "(bach_size,seq_length,nodenum,features)\n",
    "for b in bach_size:\n",
    "    #(seq_length,nodenum,features)\n",
    "    #gatlayer\n",
    "    #(seq_length,nodenum,features)\n",
    "    for s in seq_length:\n",
    "        (nodenum,features)\n",
    "        gatlayer\n",
    "        (nodenum,features)\n",
    "        (nodenum,features)\n",
    "        LSTM\n",
    "    predict(nodenum,aqi)\n",
    "（seq_length,nodenum,features）\n",
    "'''\n",
    "def load_data(distance,nodenum,train_test):\n",
    "    data = np.load('../data/fourCity.npy')\n",
    "    data[np.isnan(data)]=0\n",
    "    A = np.load('../data/fourCityA.npy')\n",
    "    A[np.isnan(A)]=0\n",
    "    A[A <= distance] = 1.\n",
    "    A[A > distance] = 0.\n",
    "    #只关心与nodenum相关的监测点\n",
    "    \n",
    "    A[:,0:nodenum,0:nodenum] = 0\n",
    "    A[:,nodenum+1:,0:nodenum] = 0\n",
    "    A[:,0:nodenum:,nodenum+1:] = 0\n",
    "    A[:,nodenum+1:,nodenum+1:] = 0\n",
    "    \n",
    "    #（city,alltime,nodenum,feature）\n",
    "    label = data[:,:,:,data.shape[2]-1:]\n",
    "    \n",
    "    #label = label[np.newaxis]\n",
    "    print(label.shape)\n",
    "    #（timestep*batchsize，node，features）\n",
    "    train = data[:,:,:,:-1]\n",
    "    #train = train[np.newaxis]\n",
    "    input_a, label_a = train[:,0:train_test,:,:],label[:,0:train_test,:]\n",
    "    input_b, label_b = train[:,train_test:,:,:],label[:,train_test:,:]\n",
    "    A = A[np.newaxis]\n",
    "    return input_a, label_a,input_b, label_b,A\n",
    "def load_data2(distance,nodenum,trainnum,testnum,targetnum):\n",
    "    data = np.load('../data/fourCity.npy')\n",
    "    data[np.isnan(data)]=0\n",
    "    A = np.load('../data/fourCityA.npy')\n",
    "    A[np.isnan(A)]=0\n",
    "    A[A <= distance] = 1.\n",
    "    A[A > distance] = 0.\n",
    "    #只关心与nodenum相关的监测点\n",
    "    \n",
    "    A[:,0:nodenum,0:nodenum] = 0\n",
    "    A[:,nodenum+1:,0:nodenum] = 0\n",
    "    A[:,0:nodenum:,nodenum+1:] = 0\n",
    "    A[:,nodenum+1:,nodenum+1:] = 0\n",
    "    \n",
    "    #（city,alltime,nodenum,feature）\n",
    "    label = data[:,:,:,data.shape[3]-1:]\n",
    "    \n",
    "    #label = label[np.newaxis]\n",
    "    print(label.shape)\n",
    "    #（timestep*batchsize，node，features）\n",
    "    train = data[:,:,:,:-1]\n",
    "    #train = train[np.newaxis]\n",
    "    #源城市\n",
    "    input_a, label_a = train[0:3,0:trainnum,:,:],label[0:3,0:trainnum,:,:]\n",
    "    input_b, label_b = train[0:3,0:testnum,:,:],label[0:3,0:testnum,:,:]\n",
    "    #目标城市\n",
    "    input_t, label_t = train[3,0:targetnum,:,:],label[3,0:targetnum,:,:]\n",
    "    input_t = input_t[np.newaxis]\n",
    "    label_t = label_t[np.newaxis]\n",
    "    #A = A[np.newaxis]\n",
    "    return input_a, label_a,input_b, label_b,input_t,label_t,A\n",
    "\n",
    "def normal(w):\n",
    "    mean = np.mean(w,axis = 0)\n",
    "    var = np.var(w,axis = 0)\n",
    "    resultW = np.round((w - mean)/np.sqrt(var +0.001),decimals = 7)\n",
    "    return resultW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, sess, saver):\n",
    "    '''\n",
    "    biasesb = np.zeros([cities,42, 42])\n",
    "    biasesb[0] = A[3,:,:]\n",
    "    biasesb[1] = A[3,:,:]\n",
    "    biasesb[2] = A[3,:,:]\n",
    "    '''\n",
    "    outputs = None\n",
    "    \n",
    "    for epoch in range(iterations): \n",
    "        \n",
    "        inputa = np.zeros([cities,update_batch_size, seq_length, 42,17])\n",
    "        inputb = np.zeros([cities,update_batch_size, seq_length, 42,17])\n",
    "        labela = np.zeros([cities,update_batch_size, 1])\n",
    "        labelb = np.zeros([cities,update_batch_size, 1])\n",
    "        #update_batch_size\n",
    "        num = 0\n",
    "        k = seq_length\n",
    "        #每一次迭代 的训练次数（batch的个数）\n",
    "        remm = 0\n",
    "        #总误差\n",
    "        sum1 = 0.0\n",
    "        sum2 = 0.0\n",
    "        #设置batch\n",
    "        for i in range(seq_length,input_a.shape[1]):\n",
    "            #batch_size\n",
    "            inputa[0][num] = input_a[0,i-seq_length:i,:,:] \n",
    "            labela[0][num][0] = label_a[0,i,node_num,0]\n",
    "            \n",
    "            inputa[1][num] = input_a[1,i-seq_length:i,:,:] \n",
    "            labela[1][num][0] = label_a[1,i,node_num,0]\n",
    "            \n",
    "            inputa[2][num] = input_a[2,i-seq_length:i,:,:] \n",
    "            labela[2][num][0] = label_a[2,i,node_num,0]\n",
    "            \n",
    "            inputb[0][num] = input_b[0,k-seq_length:k,:,:] \n",
    "            labelb[0][num][0] = label_b[0,k,node_num,0]\n",
    "            inputb[1][num] = input_b[1,k-seq_length:k,:,:] \n",
    "            labelb[1][num][0] = label_b[1,k,node_num,0]\n",
    "            inputb[2][num] = input_b[2,k-seq_length:k,:,:] \n",
    "            labelb[2][num][0] = label_b[2,k,node_num,0]\n",
    "            \n",
    "            k = k + 1\n",
    "            if k == input_b.shape[1]:\n",
    "                k = seq_length \n",
    "            num = num + 1\n",
    "            #凑够一个batch\n",
    "            if num % update_batch_size == 0: \n",
    "                num = 0\n",
    "                #train\n",
    "                feed_dict = {model.inputa: inputa, \n",
    "                             model.inputb: inputb,\n",
    "                             model.labela: labela, \n",
    "                             model.labelb: labelb,\n",
    "                             #ftr_in: features[vl_step*batch_size:(vl_step+1)*batch_size],\n",
    "                             model.bias_ina: biasesa,\n",
    "                             model.bias_inb: biasesb,\n",
    "                             #lbl_in: y_val[vl_step*batch_size:(vl_step+1)*batch_size],\n",
    "                             #model.msk_in: val_mask,\n",
    "                             model.is_train: True,\n",
    "                             model.attn_drop: 0.0, model.ffd_drop: 0.0\n",
    "                        }\n",
    "                remm = remm + 1\n",
    "                \n",
    "                if epoch % 10 == 0:\n",
    "                    #model_file = 'model' + \"/\" + model_type + \"/model_\" + str(epoch)\n",
    "                    #saver.save(sess, model_file)\n",
    "                    res = sess.run([model.total_rmse1, model.total_rmse2,model.outputas, model.outputbs], feed_dict)\n",
    "                    outputas = res[2]\n",
    "                    outputbs = res[3]\n",
    "                    sum1 = sum1 + res[0][0]\n",
    "                    sum2 = sum2 + res[1][0]\n",
    "                    print('【res】',epoch, res[0:2])\n",
    "                    #绘制图像\n",
    "                    if remm == 50:\n",
    "                        rowdataa = pd.DataFrame(labela[0],columns=['predict'])\n",
    "                        rowdataa.to_csv('rowdataa50.csv')\n",
    "                        labela_ = normal(labela[0])\n",
    "                        rowdatab = pd.DataFrame(labelb[0],columns=['predict'])\n",
    "                        rowdatab.to_csv('rowdatab50.csv')\n",
    "                        labelb_ = normal(labelb[0])\n",
    "                        fig = plt.figure()\n",
    "                        plt.rc('figure',figsize=(20,10))\n",
    "                        ax0 = fig.add_subplot(2,1,1)\n",
    "                        ax1 = fig.add_subplot(2,1,2)\n",
    "                        #训练\n",
    "                        writedataoa = pd.DataFrame(outputas[0],columns=['predict'])\n",
    "                        writedataoa.to_csv('outputa'+ str(epoch) +'.csv')\n",
    "                        writedatala = pd.DataFrame(labela_,columns=['observer'])\n",
    "                        writedatala.to_csv('labela'+str(epoch)+'.csv')\n",
    "                        ax0.plot(outputas[0],'red',label='predict')\n",
    "                        ax0.plot(labela_,'blue',label='observer')\n",
    "                        #测试\n",
    "                        writedataob = pd.DataFrame(outputbs[0][0],columns=['predict'])\n",
    "                        writedataob.to_csv('outputb'+ str(epoch) +'.csv')\n",
    "                        writedatalb = pd.DataFrame(labelb_,columns=['observer'])\n",
    "                        writedatalb.to_csv('labelb'+str(epoch)+'.csv')\n",
    "                        ax1.plot(outputbs[0][0],'red',label='predict')\n",
    "                        ax1.plot(labelb_,'blue',label='observer')\n",
    "                        plt.show()\n",
    "                    \n",
    "                else:\n",
    "                    #元训练\n",
    "                    if \"meta\" in model_type:\n",
    "                        sess.run([model.metatrain_op], feed_dict)\n",
    "                    elif \"pretrain\" in model_type:\n",
    "                    #预训练\n",
    "                        sess.run([model.pretrain_op], feed_dict)\n",
    "        \n",
    "        print('训练集平均rmes',sum1/remm)\n",
    "        print('测试集平均rmes',sum2/remm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model, sess, saver):\n",
    "    \n",
    "    for epoch in range(iterations): \n",
    "        inputa = np.zeros([cities,update_batch_size, seq_length, 42,17])        \n",
    "        labela = np.zeros([cities,update_batch_size, 1])\n",
    "        #update_batch_size\n",
    "        num = 0\n",
    "        #每一次迭代 的训练次数\n",
    "        remm = 0\n",
    "        #总误差\n",
    "        sum1 = 0.0\n",
    "        sum2 = 0.0\n",
    "        \n",
    "        total_test_loss = []\n",
    "        total_outputa = []\n",
    "        \n",
    "        for i in range(seq_length,input_a.shape[1]):\n",
    "            #batch_size\n",
    "            inputa[0][num] = input_a[0,i-seq_length:i,:,:] \n",
    "            labela[0][num][0] = label_a[0,i,node_num,0]\n",
    "            \n",
    "            inputa[1][num] = input_a[0,i-seq_length:i,:,:] \n",
    "            labela[1][num][0] = label_a[0,i,node_num,0]\n",
    "            \n",
    "            inputa[2][num] = input_a[0,i-seq_length:i,:,:] \n",
    "            labela[2][num][0] = label_a[0,i,node_num,0]\n",
    "        \n",
    "            num = num + 1\n",
    "            if num % update_batch_size == 0: \n",
    "                num = 0                \n",
    "                feed_dict = {model.inputa: inputa, model.labela: labela, model.bias_ina: biasest, model.is_train: False,\n",
    "                             model.attn_drop: 0.0, model.ffd_drop: 0.0}                        \n",
    "                remm = remm + 1\n",
    "                outputa, loss1, = sess.run([model.outputas, model.total_loss1], feed_dict)\n",
    "                total_outputa.append(outputa)\n",
    "                total_test_loss.append(loss1)\n",
    "        #total_outputa = np.concatenate(total_outputa, axis=1)\n",
    "        print(epoch, np.sqrt(np.mean(total_test_loss)))                   \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta False True\n",
      "Initializing STDN...\n",
      "Initializing construct_model...\n",
      "(3, 64, 7, 42, 17)\n",
      "Initializing forward...\n",
      "(64, 7, 42, 17)\n",
      "Initializing forward_convlstm...\n",
      "(64, 7, 42, 17)\n",
      "Initializing LSTM...\n",
      "【inp】 [<tf.Tensor 'model/map/while/unstack:0' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack:1' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack:2' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack:3' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack:4' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack:5' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack:6' shape=(64, 42, 17) dtype=float32>]\n",
      "【state】 [<tf.Tensor 'model/map/while/zeros:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'model/map/while/zeros_1:0' shape=(64, 128) dtype=float32>]\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_1/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_1/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_1/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_2/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_2/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_2/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_3/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_3/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_3/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_4/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_4/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_4/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE125A60>\n",
      "【logits】 Tensor(\"model/map/while/truediv:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_2:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_5/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_5/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_5/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_6/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_6/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_6/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_7/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_7/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_7/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_8/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_8/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_8/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_2:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_9/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_9/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_9/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE125D08>\n",
      "【logits】 Tensor(\"model/map/while/truediv_1:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_1:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_1:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_1:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_5:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_10/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_10/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_10/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_11/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_11/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_11/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_12/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_12/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_12/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_13/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_13/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_13/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_4:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_14/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_14/add:0\", shape=(64, 42, 42), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【coefs】 Tensor(\"model/map/while/my_attn_14/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE125AE8>\n",
      "【logits】 Tensor(\"model/map/while/truediv_2:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_2:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_2:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_2:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_8:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_15/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_15/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_15/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_16/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_16/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_16/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_17/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_17/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_17/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_18/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_18/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_18/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_6:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_19/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_19/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_19/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE125378>\n",
      "【logits】 Tensor(\"model/map/while/truediv_3:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_3:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_3:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_3:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_11:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_20/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_20/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_20/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_21/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_21/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_21/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_22/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_22/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_22/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_23/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_23/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_23/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_8:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_24/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_24/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_24/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE125D90>\n",
      "【logits】 Tensor(\"model/map/while/truediv_4:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_4:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_4:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_4:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_14:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_25/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_25/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_25/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_26/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_26/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_26/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_27/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_27/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_27/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_28/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_28/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_28/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_10:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_29/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_29/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_29/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE1251E0>\n",
      "【logits】 Tensor(\"model/map/while/truediv_5:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_5:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_5:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_5:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_17:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_30/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_30/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_30/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_31/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_31/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_31/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_32/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【logits】 Tensor(\"model/map/while/my_attn_32/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_32/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_33/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_33/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_33/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_12:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_34/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_34/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_34/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6BE1258C8>\n",
      "【logits】 Tensor(\"model/map/while/truediv_6:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_6:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_6:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_6:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_20:0\", shape=(64, 128), dtype=float32)\n",
      "【lstm_outputs】 Tensor(\"model/map/while/Mul_20:0\", shape=(64, 128), dtype=float32)\n",
      "【preds】 Tensor(\"model/map/while/Tanh_14:0\", shape=(64, 1), dtype=float32)\n",
      "【pred】 Tensor(\"model/map/while/Tanh_14:0\", shape=(64, 1), dtype=float32)\n",
      "【label】 Tensor(\"model/map/while/batchnorm/add_1:0\", shape=(64, 1), dtype=float32)\n",
      "【weights】 {'weight': <tf.Variable 'model/maml/weight:0' shape=(1, 17, 8) dtype=float32_ref>, 'att_self_weight': <tf.Variable 'model/maml/att_self_weight:0' shape=(1, 8, 1) dtype=float32_ref>, 'att_neighs_weight': <tf.Variable 'model/maml/att_neighs_weight:0' shape=(1, 8, 1) dtype=float32_ref>, 'bias_weight': <tf.Variable 'model/maml/bias_weight:0' shape=(8,) dtype=float32_ref>, 'output_weight': <tf.Variable 'model/maml/output_weight:0' shape=(1, 32, 17) dtype=float32_ref>, 'output_att_self_weight': <tf.Variable 'model/maml/output_att_self_weight:0' shape=(1, 17, 1) dtype=float32_ref>, 'output_att_neighs_weight': <tf.Variable 'model/maml/output_att_neighs_weight:0' shape=(1, 17, 1) dtype=float32_ref>, 'output_bias_weight': <tf.Variable 'model/maml/output_bias_weight:0' shape=(17,) dtype=float32_ref>, 'kernel_lstm': <tf.Variable 'model/maml/kernel_lstm:0' shape=(145, 512) dtype=float32_ref>, 'b_lstm': <tf.Variable 'model/maml/Variable:0' shape=(512,) dtype=float32_ref>, 'b_fc2': <tf.Variable 'model/maml/Variable_1:0' shape=(1,) dtype=float32_ref>, 'fc2': <tf.Variable 'model/maml/fc6:0' shape=(128, 1) dtype=float32_ref>}\n",
      "Initializing forward...\n",
      "(64, 7, 42, 17)\n",
      "Initializing forward_convlstm...\n",
      "(64, 7, 42, 17)\n",
      "Initializing LSTM...\n",
      "【inp】 [<tf.Tensor 'model/map/while/unstack_1:0' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack_1:1' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack_1:2' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack_1:3' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack_1:4' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack_1:5' shape=(64, 42, 17) dtype=float32>, <tf.Tensor 'model/map/while/unstack_1:6' shape=(64, 42, 17) dtype=float32>]\n",
      "【state】 [<tf.Tensor 'model/map/while/zeros_2:0' shape=(64, 128) dtype=float32>, <tf.Tensor 'model/map/while/zeros_3:0' shape=(64, 128) dtype=float32>]\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_35/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_35/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_35/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_36/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_36/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_36/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_37/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_37/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_37/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_38/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_38/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_38/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_14:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_39/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_39/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_39/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3E270D0>\n",
      "【logits】 Tensor(\"model/map/while/truediv_7:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_7:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_8:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_7:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_35:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_40/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_40/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_40/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_41/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_41/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_41/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_42/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_42/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_42/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_43/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_43/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_43/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_16:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_44/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_44/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_44/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3E27400>\n",
      "【logits】 Tensor(\"model/map/while/truediv_8:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_8:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_9:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_8:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_38:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_45/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_45/add:0\", shape=(64, 42, 42), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【coefs】 Tensor(\"model/map/while/my_attn_45/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_46/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_46/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_46/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_47/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_47/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_47/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_48/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_48/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_48/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_18:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_49/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_49/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_49/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3D9BD90>\n",
      "【logits】 Tensor(\"model/map/while/truediv_9:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_9:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_10:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_9:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_41:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_50/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_50/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_50/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_51/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_51/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_51/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_52/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_52/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_52/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_53/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_53/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_53/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_20:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_54/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_54/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_54/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3E27268>\n",
      "【logits】 Tensor(\"model/map/while/truediv_10:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_10:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_11:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_10:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_44:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_55/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_55/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_55/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_56/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_56/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_56/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_57/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_57/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_57/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_58/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_58/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_58/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_22:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_59/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_59/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_59/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3E276A8>\n",
      "【logits】 Tensor(\"model/map/while/truediv_11:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_11:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_12:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_11:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_47:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_60/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_60/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_60/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_61/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_61/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_61/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_62/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_62/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_62/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_63/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_63/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_63/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_24:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_64/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_64/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_64/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3E27730>\n",
      "【logits】 Tensor(\"model/map/while/truediv_12:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_12:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_13:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_12:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_50:0\", shape=(64, 128), dtype=float32)\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_65/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_65/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_65/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_66/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_66/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_66/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_67/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_67/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_67/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【seq】 (64, 42, 17)\n",
      "【weight】 Tensor(\"model/map/while/sub_1:0\", shape=(1, 17, 8), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_68/conv1d/Squeeze:0\", shape=(64, 42, 8), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_68/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_68/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function elu at 0x000000E6B6A3AC80>\n",
      "【hid_units】 1\n",
      "【h_1】 Tensor(\"model/map/while/concat_26:0\", shape=(64, 42, 32), dtype=float32)\n",
      "【seq】 (64, 42, 32)\n",
      "【weight】 Tensor(\"model/map/while/sub_5:0\", shape=(1, 32, 17), dtype=float32)\n",
      "【seq_fts】 Tensor(\"model/map/while/my_attn_69/conv1d/Squeeze:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【logits】 Tensor(\"model/map/while/my_attn_69/add:0\", shape=(64, 42, 42), dtype=float32)\n",
      "【coefs】 Tensor(\"model/map/while/my_attn_69/dropout_1/mul:0\", shape=(64, 42, 42), dtype=float32)\n",
      "<function GAT.inference.<locals>.<lambda> at 0x000000E6C3E27268>\n",
      "【logits】 Tensor(\"model/map/while/truediv_13:0\", shape=(64, 42, 17), dtype=float32)\n",
      "【c】 (64, 128)\n",
      "【h】 (64, 128)\n",
      "【linp】 Tensor(\"model/map/while/strided_slice_13:0\", shape=(64, 17), dtype=float32)\n",
      "【kweight】 Tensor(\"model/map/while/sub_9:0\", shape=(145, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/MatMul_14:0\", shape=(64, 512), dtype=float32)\n",
      "【gate_inputs】 Tensor(\"model/map/while/BiasAdd_13:0\", shape=(64, 512), dtype=float32)\n",
      "【new_h】 Tensor(\"model/map/while/Mul_53:0\", shape=(64, 128), dtype=float32)\n",
      "【lstm_outputs】 Tensor(\"model/map/while/Mul_53:0\", shape=(64, 128), dtype=float32)\n",
      "【preds】 Tensor(\"model/map/while/Tanh_29:0\", shape=(64, 1), dtype=float32)\n",
      "【pred】 Tensor(\"model/map/while/Tanh_29:0\", shape=(64, 1), dtype=float32)\n",
      "【label】 Tensor(\"model/map/while/batchnorm_1/add_1:0\", shape=(64, 1), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-5-ed1ca293fab4>:54: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:`tf.train.start_queue_runners()` was called when no queue runners were defined. You can safely remove the call to this deprecated function.\n",
      "Data generate:\n",
      "(4, 8632, 42, 1)\n",
      "Training: meta\n",
      "【res】 0 [array([0.6958838 , 1.21233   , 0.87444836], dtype=float32), [0.9421199]]\n",
      "【res】 0 [array([0.95543677, 1.3180859 , 0.9047634 ], dtype=float32), [1.0644141]]\n",
      "【res】 0 [array([1.0133698 , 1.4010204 , 0.87274456], dtype=float32), [1.1052698]]\n",
      "【res】 0 [array([1.0490494, 1.653899 , 1.1212484], dtype=float32), [1.2893133]]\n",
      "【res】 0 [array([1.2305199, 1.2800922, 0.8181149], dtype=float32), [1.1188785]]\n",
      "【res】 0 [array([1.1321713 , 0.98170274, 1.046275  ], dtype=float32), [1.0314157]]\n",
      "【res】 0 [array([0.9499455 , 1.1247628 , 0.85355264], dtype=float32), [0.96935797]]\n",
      "【res】 0 [array([0.8806523, 1.3996965, 1.162229 ], dtype=float32), [1.1456451]]\n",
      "【res】 0 [array([1.5431869, 1.2495756, 1.2457395], dtype=float32), [1.3265554]]\n",
      "【res】 0 [array([1.1031386, 1.042111 , 0.9580094], dtype=float32), [1.0168597]]\n",
      "【res】 0 [array([1.2033712 , 0.90754026, 1.0860947 ], dtype=float32), [1.0381066]]\n",
      "【res】 0 [array([1.274554 , 1.2192259, 1.0101143], dtype=float32), [1.1488372]]\n",
      "【res】 0 [array([0.71335983, 1.4743259 , 1.357605  ], dtype=float32), [1.2080405]]\n",
      "【res】 0 [array([1.3603963 , 1.1732742 , 0.98532706], dtype=float32), [1.1700447]]\n",
      "【res】 0 [array([1.1056894, 1.3893238, 1.1164972], dtype=float32), [1.1943824]]\n",
      "【res】 0 [array([0.80841595, 1.2625724 , 0.67628473], dtype=float32), [0.93781453]]\n",
      "【res】 0 [array([1.1998442, 0.9192194, 1.2064083], dtype=float32), [1.1021214]]\n",
      "【res】 0 [array([1.277071 , 1.0273553, 1.1993139], dtype=float32), [1.1411091]]\n",
      "【res】 0 [array([1.2317427, 1.2675312, 0.789345 ], dtype=float32), [1.0980607]]\n",
      "【res】 0 [array([1.1354   , 1.1789693, 1.2919912], dtype=float32), [1.1597419]]\n",
      "【res】 0 [array([1.0212128, 1.1352232, 1.3010373], dtype=float32), [1.1152174]]\n",
      "【res】 0 [array([0.73419  , 1.3846796, 0.8801268], dtype=float32), [1.0164366]]\n",
      "【res】 0 [array([0.8597349 , 1.294275  , 0.96109873], dtype=float32), [1.0268729]]\n",
      "【res】 0 [array([1.1092589 , 0.96730167, 1.1779492 ], dtype=float32), [1.0713438]]\n",
      "【res】 0 [array([1.1477576, 1.1889958, 1.0906483], dtype=float32), [1.1137193]]\n",
      "【res】 0 [array([0.7941922 , 0.64330524, 1.4180713 ], dtype=float32), [0.9943733]]\n",
      "【res】 0 [array([0.7754185, 1.0485787, 1.0120909], dtype=float32), [0.92449963]]\n",
      "【res】 0 [array([1.2914344, 1.4168946, 1.1582035], dtype=float32), [1.2553655]]\n",
      "【res】 0 [array([0.9230674, 0.9752732, 1.0382887], dtype=float32), [0.95830655]]\n",
      "【res】 0 [array([1.1745775 , 0.72086775, 0.98639345], dtype=float32), [0.9511402]]\n",
      "【res】 0 [array([0.9542131 , 0.91171277, 1.1321929 ], dtype=float32), [0.9837648]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【res】 0 [array([1.1117657, 1.3718207, 1.0221926], dtype=float32), [1.1156614]]\n",
      "【res】 0 [array([1.1902876, 1.1535658, 1.138532 ], dtype=float32), [1.1151778]]\n",
      "【res】 0 [array([1.3061112, 0.9942597, 1.2070522], dtype=float32), [1.150657]]\n",
      "【res】 0 [array([1.053153 , 1.0391935, 1.2282127], dtype=float32), [1.2857305]]\n",
      "【res】 0 [array([1.0742711, 1.098338 , 1.0843098], dtype=float32), [1.0732857]]\n",
      "【res】 0 [array([1.2135255, 1.047672 , 1.2543385], dtype=float32), [1.0248579]]\n",
      "【res】 0 [array([1.3386747, 1.5822978, 1.3114598], dtype=float32), [0.88568985]]\n",
      "【res】 0 [array([1.0941784, 0.9836666, 1.0111014], dtype=float32), [1.2348471]]\n",
      "【res】 0 [array([0.9747184, 1.0640719, 1.5244586], dtype=float32), [1.3046049]]\n",
      "【res】 0 [array([1.4287384 , 0.98876166, 1.0675448 ], dtype=float32), [1.047755]]\n",
      "【res】 0 [array([1.241928 , 1.1626238, 1.5425186], dtype=float32), [1.1587853]]\n",
      "【res】 0 [array([0.7599313, 1.3528603, 0.8211165], dtype=float32), [1.2466509]]\n",
      "【res】 0 [array([1.575928, 1.171713, 1.131628], dtype=float32), [1.0251577]]\n",
      "【res】 0 [array([1.2156357 , 0.83793485, 1.3215508 ], dtype=float32), [1.0798376]]\n",
      "【res】 0 [array([1.4205401, 1.3159901, 1.1252785], dtype=float32), [1.0979414]]\n",
      "【res】 0 [array([1.344031  , 0.78774893, 1.2618896 ], dtype=float32), [0.94966984]]\n",
      "【res】 0 [array([1.0290332, 0.8083481, 1.2129422], dtype=float32), [1.1062602]]\n",
      "【res】 0 [array([1.2453697, 1.0735165, 1.0706164], dtype=float32), [1.0594432]]\n",
      "【res】 0 [array([1.2329445, 1.0005983, 1.1944562], dtype=float32), [1.0019042]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n12g0mjBDK3aNRqMJM7Ri12g0mjDj/wFKrpquEusa0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe6def96160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【res】 0 [array([1.3289348, 1.3020731, 1.376832 ], dtype=float32), [1.2480707]]\n",
      "【res】 0 [array([1.223005 , 1.607516 , 0.9182957], dtype=float32), [1.1488283]]\n",
      "【res】 0 [array([1.2623123 , 1.2137694 , 0.96919227], dtype=float32), [1.0697206]]\n",
      "【res】 0 [array([1.2040107, 1.279299 , 1.030049 ], dtype=float32), [1.1205186]]\n",
      "【res】 0 [array([0.97148407, 1.2913233 , 0.69921094], dtype=float32), [1.1216174]]\n",
      "【res】 0 [array([1.3113834, 1.0460887, 1.0899187], dtype=float32), [1.1281699]]\n",
      "【res】 0 [array([0.7452421, 1.3191098, 1.0388098], dtype=float32), [1.0622705]]\n",
      "【res】 0 [array([1.1334907, 1.2713032, 1.0399615], dtype=float32), [1.0510198]]\n",
      "【res】 0 [array([1.1018978 , 1.543856  , 0.80968595], dtype=float32), [1.2357534]]\n",
      "【res】 0 [array([1.0145139, 1.0584407, 1.4403534], dtype=float32), [1.0724387]]\n",
      "【res】 0 [array([1.1494302, 1.6015509, 0.9775612], dtype=float32), [0.88662857]]\n",
      "【res】 0 [array([1.1737967, 1.3546387, 1.132202 ], dtype=float32), [0.9618643]]\n",
      "【res】 0 [array([1.4290463 , 1.055025  , 0.73192555], dtype=float32), [1.126493]]\n",
      "【res】 0 [array([0.9947026 , 1.2033546 , 0.96945536], dtype=float32), [1.0950757]]\n",
      "【res】 0 [array([1.402598 , 1.1556733, 1.2969713], dtype=float32), [1.1702954]]\n",
      "【res】 0 [array([0.7878885, 1.4141979, 1.1506176], dtype=float32), [1.3659903]]\n",
      "【res】 0 [array([1.0354569 , 1.2712802 , 0.94316065], dtype=float32), [1.0866016]]\n",
      "【res】 0 [array([0.97389627, 1.0270656 , 1.2688509 ], dtype=float32), [1.0208646]]\n",
      "【res】 0 [array([1.1629279, 1.1643554, 0.9694247], dtype=float32), [0.9236992]]\n",
      "【res】 0 [array([1.1228524, 1.6896809, 0.9049148], dtype=float32), [1.1874653]]\n",
      "【res】 0 [array([1.1927508, 1.4587598, 1.270485 ], dtype=float32), [1.3006551]]\n",
      "【res】 0 [array([1.1038574, 1.3864115, 1.2309816], dtype=float32), [1.1198492]]\n",
      "【res】 0 [array([1.0330064 , 1.2910848 , 0.93547094], dtype=float32), [1.2269307]]\n",
      "【res】 0 [array([0.8466131, 1.5310127, 0.9011668], dtype=float32), [1.1863654]]\n",
      "【res】 0 [array([1.0521879 , 1.3665261 , 0.91074646], dtype=float32), [1.0754943]]\n",
      "【res】 0 [array([0.96932536, 1.6972953 , 1.0511748 ], dtype=float32), [1.0710851]]\n",
      "【res】 0 [array([0.78301233, 1.7254066 , 1.2357894 ], dtype=float32), [0.9925893]]\n",
      "【res】 0 [array([0.91852427, 1.3954982 , 1.1037482 ], dtype=float32), [0.998589]]\n",
      "【res】 0 [array([1.4796854, 1.1632481, 0.7132793], dtype=float32), [1.1884676]]\n",
      "【res】 0 [array([1.2254817, 1.679611 , 1.1922516], dtype=float32), [0.9077858]]\n",
      "【res】 0 [array([1.3215408, 1.4777251, 1.257824 ], dtype=float32), [1.0407485]]\n",
      "【res】 0 [array([0.9850327 , 1.2468275 , 0.85176456], dtype=float32), [1.2538947]]\n",
      "【res】 0 [array([0.9423236, 1.1082321, 1.1063861], dtype=float32), [1.1441916]]\n",
      "【res】 0 [array([1.1234713 , 1.6568115 , 0.94425714], dtype=float32), [1.104407]]\n",
      "【res】 0 [array([1.2652628, 1.3401097, 0.706793 ], dtype=float32), [1.1405945]]\n",
      "【res】 0 [array([0.9572917, 1.2143209, 1.0733541], dtype=float32), [1.0380555]]\n",
      "【res】 0 [array([1.0271477, 1.4230279, 1.2528628], dtype=float32), [1.0653884]]\n",
      "【res】 0 [array([0.9902949, 1.2605278, 1.3355252], dtype=float32), [1.1110824]]\n",
      "【res】 0 [array([1.0668185, 1.7429086, 1.2769082], dtype=float32), [1.0765154]]\n",
      "【res】 0 [array([1.0813873, 1.5814484, 1.2985198], dtype=float32), [1.2075264]]\n",
      "【res】 0 [array([0.951538 , 1.1005199, 1.4338211], dtype=float32), [1.095604]]\n",
      "【res】 0 [array([0.6990421, 1.2148769, 1.3443582], dtype=float32), [0.90539134]]\n",
      "【res】 0 [array([1.3397434 , 1.3227146 , 0.72737783], dtype=float32), [0.9522288]]\n",
      "训练集平均rmes 1.1008949632285743\n",
      "测试集平均rmes 1.0953749668213628\n"
     ]
    }
   ],
   "source": [
    "#def main():\n",
    "\n",
    "model_type = 'meta'\n",
    "tf.set_random_seed(1234)\n",
    "print(model_type, \"att\" in model_type, \"meta\" in model_type)\n",
    "meta_lr = 1e-4\n",
    "update_lr = 2e-4\n",
    "cities = 3\n",
    "\n",
    "#update_batch_size = alltime / seq_length\n",
    "update_batch_size = 64\n",
    "\n",
    "'''\n",
    "(cities,alltime,seq_len,nodenum,features)\n",
    "(alltime,seq_len,nodenum,features)\n",
    "for i in alltime:\n",
    "    (seq_len,nodenum,features)\n",
    "    for i in seq_len:\n",
    "        (nodenum,features)\n",
    "        gat\n",
    "        {\n",
    "        \n",
    "        }\n",
    "'''\n",
    "#站点距离阈值\n",
    "distance = 20.0\n",
    "test_num_updates = 1\n",
    "dim_output = 1\n",
    "dim_input = 8\n",
    "seq_length = 7\n",
    "hid_units = [8] # numbers of hidden units per each attention head in each layer\n",
    "n_heads = [4, 1] # additional entry for the output layer\n",
    "residual = False\n",
    "nonlinearity = tf.nn.relu\n",
    "iterations = 50\n",
    "#测试的监测站id（0-42）\n",
    "node_num = 8\n",
    "\n",
    "model = STDN(dim_input=dim_input, dim_output=dim_output, seq_length=seq_length,node_num=node_num,\n",
    "                     filter_num=64, dim_cnn_flatten=7*7*64,\n",
    "                     dim_fc=16, dim_lstm_hidden=128,\n",
    "                     update_lr=update_lr, meta_lr=meta_lr,\n",
    "                     meta_batch_size=cities,\n",
    "                     update_batch_size=update_batch_size,\n",
    "                     test_num_updates=test_num_updates,\n",
    "                     feature_size=17, nb_nodes=42,\n",
    "                     hid_units=hid_units, n_heads=n_heads,\n",
    "                     residual=residual, activation=nonlinearity)\n",
    "model.construct_model()\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES), max_to_keep=10)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "tf.train.start_queue_runners()\n",
    "\n",
    "#data_generator = DataGenerator(dim_input=dim_input,\n",
    "                                   #dim_output=dim_output,\n",
    "                                   #seq_length=seq_length,\n",
    "                                   #threshold=threshold)\n",
    "#if dim_output == 2:\n",
    "    #data_generator.load_train_data(cities=cities, train_prop=0.8, select_data='all')\n",
    "#else:\n",
    "    #data_generator.load_train_data(cities=cities, train_prop=0.8, select_data='pick')\n",
    "\n",
    "print(\"Data generate:\")\n",
    "trainnum = 6000\n",
    "testnum = 2000\n",
    "targetnum = 4800\n",
    "drowtime = (trainnum / 60)\n",
    "input_a, label_a,input_b, label_b,input_t,label_t,A = load_data2(distance,node_num,trainnum,testnum,targetnum)\n",
    "biasesa = A[0:3,:,:]\n",
    "biasesb = biasesa\n",
    "print(\"Training:\", model_type)\n",
    "train(model, sess, saver)\n",
    "print(\"Test:\")\n",
    "biasest = np.zeros([cities,42, 42])\n",
    "biasest[0] = A[3,:,:]\n",
    "biasest[1] = A[3,:,:]\n",
    "biasest[2] = A[3,:,:]\n",
    "test(model, sess, saver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
